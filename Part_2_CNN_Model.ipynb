{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os, itertools\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + \"/configs/\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.config.experimental import list_physical_devices\n",
    "gpu_devices = list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "else:\n",
    "    print('Using CPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_WIDTH, IMAGE_HEIGHT = 50, 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_data = np.load('Xs.npy',allow_pickle=True)\n",
    "ys_data = np.load('ys.npy',allow_pickle=True)\n",
    "print(\"Xs:\",Xs_data.shape)\n",
    "print(\"ys:\",ys_data.shape)\n",
    "print(\"Class label count:\",sorted(Counter(ys_data).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for MinMaxScaler and RandomUnderSampler \n",
    "Xs_data = Xs_data.reshape((len(Xs_data),(IMAGE_HEIGHT*IMAGE_WIDTH)))\n",
    "ys_data = ys_data\n",
    "print(\"Xs:\",Xs_data.shape)\n",
    "print(\"ys:\",ys_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' RandomUnderSampler for classification imbalance of Hold labels'''\n",
    "# !pip install -U imbalanced-learn\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# rus = RandomUnderSampler()\n",
    "# Xs, ys = rus.fit_resample(Xs_data, ys_data)\n",
    "# print(\"Xs:\",Xs.shape)\n",
    "# print(\"ys:\",ys.shape)\n",
    "# print(\"Class label count:\",sorted(Counter(ys).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = Xs_data\n",
    "ys = ys_data\n",
    "''' Reshape again if needed before train test split'''\n",
    "# Xs = Xs.reshape(-1,(IMAGE_HEIGHT),(IMAGE_WIDTH),1)\n",
    "# ys = ys.reshape(-1,1)\n",
    "# print(\"Xs:\",Xs.shape)\n",
    "# print(\"ys:\",ys.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xs, ys, test_size=0.20, random_state=0, shuffle=True, stratify=ys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(\"X_train:\",X_train.shape)\n",
    "print(\"X_test:\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "logisticregression = LogisticRegression(C=1, multi_class='ovr', max_iter=1000).fit(X_train, y_train)#Evaluate Logistic Regression model:\n",
    "\n",
    "print(\"training set score: %f\" % logisticregression.score(X_train, y_train))\n",
    "print(\"test set score: %f\" % logisticregression.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Reshape back to Image format for CNN '''\n",
    "X_train = X_train.reshape(-1,(IMAGE_HEIGHT),(IMAGE_WIDTH),1)\n",
    "y_train = y_train.reshape(-1,1)\n",
    "X_test = X_test.reshape(-1,(IMAGE_HEIGHT),(IMAGE_WIDTH),1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print(\"X_train:\",X_train.shape)\n",
    "print(\"y_train:\",y_train.shape)\n",
    "print(\"X_test:\",X_test.shape)\n",
    "print(\"y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' CNN model that is trained and tested on entire dataset '''\n",
    "model = Sequential()#add model layers\n",
    "model.add(Conv2D(32, (5,5), activation='relu', input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH,1)))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Conv2D(64, (5,5), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), verbose=1, batch_size=100, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score,precision_score,recall_score, f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "results = model.evaluate(X_test,y_test,verbose=0)\n",
    "loss, accuracy = results\n",
    "print(\"\\nTest Data Results\\n------------------\")\n",
    "# print(\"Test Loss: %.2f%%\" % (loss * 100))\n",
    "print(\"Test Accuracy: %.2f%%\" % (accuracy * 100))\n",
    "predictions = model.predict(X_test,verbose=0)\n",
    "classes = np.argmax(predictions, axis=1)\n",
    "f1 = f1_score(y_test, classes, average='weighted')\n",
    "print(f\"\\nF1 score: {f1}\")\n",
    "rc = recall_score(y_test, classes, average='weighted')\n",
    "print(f\"\\nRecall score: {rc}\")\n",
    "pr = precision_score(y_test, classes, average='weighted')\n",
    "print(f\"\\nPrecision score: {pr}\")\n",
    "cr = classification_report(y_test, classes,target_names=['Sell','Hold','Buy'] )\n",
    "print(f\"\\n{cr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot confusion matrix '''\n",
    "axlabels = ['Sell','Hold','Buy']\n",
    "aylabels = ['Sell','Hold','Buy']\n",
    "cf_matrix = confusion_matrix(y_test, classes, normalize='all')\n",
    "s=sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, fmt='.2%', cmap='Blues',xticklabels=axlabels, yticklabels=aylabels)\n",
    "s.set_xlabel('Predicted Label', fontsize=14)\n",
    "s.set_ylabel('True Label', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Plot train and test accuracy vs epoch chart '''\n",
    "sns.set(style=\"ticks\", context=\"talk\")\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "plt.plot(history.history['accuracy'], color=\"yellow\")\n",
    "plt.plot(history.history['val_accuracy'], color=\"green\")\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train accuracy', 'test accuracy'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(file_name):\n",
    "    ''' Save the model as an h5 file'''\n",
    "    model.save(file_name + \".h5\", overwrite=True)\n",
    "    # model.save( os.path.join(path, \"model.h5\") )\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "# save_model('save_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K FOLD CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "input_train = X_train\n",
    "input_test = X_test\n",
    "target_train = y_train\n",
    "target_test = y_test\n",
    "\n",
    "# Model configuration\n",
    "batch_size = 100\n",
    "img_width, img_height, img_num_channels = IMAGE_HEIGHT, IMAGE_WIDTH, 1\n",
    "loss_function = 'sparse_categorical_crossentropy'\n",
    "no_classes = 3\n",
    "no_epochs = 100\n",
    "optimizer = 'Adam'\n",
    "verbosity = 1\n",
    "num_folds = 5\n",
    "\n",
    "# Determine shape of the data\n",
    "input_shape = (img_width, img_height, img_num_channels)\n",
    "\n",
    "# Parse numbers as floats\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Define per-fold score containers \n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "# Merge inputs and targets\n",
    "inputs = np.concatenate((input_train, input_test), axis=0)\n",
    "targets = np.concatenate((target_train, target_test), axis=0)\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(inputs, targets):\n",
    "  # Define the model architecture\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "  model.add(Dropout(0.20))\n",
    "  model.add(Conv2D(64, kernel_size=(5, 5), activation='relu'))\n",
    "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "  model.add(Dropout(0.25))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dropout(0.50))\n",
    "  model.add(Dense(no_classes, activation='softmax'))\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(loss=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "\n",
    "  # Generate a print\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "  history = (model.fit(inputs[train], targets[train],\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity))\n",
    "\n",
    "  # Generate generalization metrics\n",
    "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
    "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "  acc_per_fold.append(scores[1] * 100)\n",
    "  loss_per_fold.append(scores[0])\n",
    "\n",
    "  # Increase fold number\n",
    "  fold_no = fold_no + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "name": "17_PartB_v2_Model.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
